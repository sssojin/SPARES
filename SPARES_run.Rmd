## How to use SPARES for survival analysis
## SPARES has 3 steps
## 1. Imputation : KNN for LTF-censored and parametric imputation for EOR-censored
## 2. Regression : After imputation, we can use any regression model
## 3. Survival probability(or duration) estimation
##    A. tuneSD : make variation in dataset
##    B. residual bootstrapping
##    C. quantile regression

## To use SPARES, need some packages and functions
## You also should have 'modeling_k_rf.rds' for flattening procedure
```{r}
source('MainFunctions.R')
source('SubFunctions.R')
source('Module.R')
```

## Example 1
## We will use example.csv file. This data has 2000 observations and 5 variables
## First column, eventtime is the survival time (Y)
## Next 4 columns are explanatory variables
## status is censoring info. 0=censored, 1=non-censored
```{r}
mydata1<-read.csv('example.csv')
dim(mydata1)
head(mydata1)
```

#myY<-mydata1$eventtime
#myX<-subset(mydata1, select=-c(eventtime,status))
#censor_info<-mydata1$status

#model options
```{r}
EOR_time=10 	#(End of research time)
K=10  			#(K in KNN imputation)
mydist='weibull'	#for EOR imputation. we support 'weibull' and 'lognormal'

```

#imputation
```{r}
mydata1.imp<-SPR_Imputation(data=mydata1, y_var='eventtime',  status_var='status',
				K=10, EoR_distn=mydist, EoR_seed=1234,EoR_time=10)
```

## now mydata1.imp has 4 attributes
## $data is imputed data
## $LTF.idx is LTF-censored observations index
## $EoR.idx is EOR-censored observations index
## $EoR.distn.params are estimated parameters for EOR imputation distribution

## Let's check Y
```{r}
plot(mydata1$eventtime,mydata1.imp$data$eventtime)
abline(0,1,col=2)
```

## we can see that all imputed values >= original values and can be larger than EOR_time
## Let's check LTF-censored observations only
```{r}
plot(mydata1$eventtime[mydata1.imp$LTF.idx],mydata1.imp$data$eventtime[mydata1.imp$LTF.idx])
abline(0,1,col=2)
```

## Now let's fit a regression model
## train/test split. 70% for train set, 30% for test set.
```{r}
n<-nrow(mydata1)
p<-0.7
train.idx<-sample(n,n*p)
mytraindata<-mydata1.imp$data[train.idx,-6]  #remove censor_info
mytestdata<-mydata1.imp$data[-train.idx,-6]
dim(mytraindata)
dim(mytestdata)
```

## let's fit RF
```{r}
rf1<-randomForest(eventtime~., data=mytraindata)
rf1.pred<-predict(rf1,mytestdata)
plot(mytestdata$eventtime,rf1.pred)
abline(0,1,col=2)
```

## looks ok. but it might be helpful to use bias-corrected RF
```{r}
sqrt(mean((rf1.pred-mytestdata$eventtime)^2))  #RMSE
```

## let's fit gbm
```{r}
library(gbm)
gbm1<-gbm(eventtime~., data=mytraindata)
gbm1.pred<-predict(gbm1,mytestdata)
plot(mytestdata$eventtime,gbm1.pred)
abline(0,1,col=2)
sqrt(mean((gbm1.pred-mytestdata$eventtime)^2))  #RMSE
```

## or you can use any other regression models, including xgboost, lightgbm, catboost, etc.

### Estimate survival probability (or survival time given survival probability)
### for each observation
### Since tuneSD method takes long time, we will show quantile regression in this example

## Linear model
```{r}
rq1<-rq(eventtime~., data=mytraindata, tau=seq(0.1,0.9,0.1))
rq1.pred<-predict(rq1,mytestdata)
mynonneg<-function(x){ifelse(x<0, 0, x)}
rq1.pred<-apply(rq1.pred,2, mynonneg) # surv time must be >=0
```

## RF model
```{r}
Y.train = mytraindata[,"eventtime"]
X.train = subset(mytraindata, select=-eventtime)
X.test=subset(mytestdata, select = -eventtime)
qrf1<-quantregForest(x=X.train, y=Y.train,nthread=16,nodesize=100,sampsize=1000)
qrf1.pred<-predict(qrf1,X.test, what=0.1*seq(1:9))		
```

## gbm model
```{r}
myalpha=seq(0.1,0.9,0.1)
gbm.res<-matrix(0,nrow=nrow(mytestdata),ncol=9)
k<-0
for (i in myalpha){

	gbm1<-gbm(eventtime~., data=mytraindata, distribution=list(name="quantile",alpha=i),
		n.trees=200, shrinkage=0.05,n.minobsinnode=100)
	gbm1.pred<-predict(gbm1,mytestdata)
	k<-k+1
	gbm.res[,k]<-gbm1.pred
}
```

## Note : we used only 0.1 to 0.9 by 0.1 to compute ASP later
## If you want to have smooth survival probability lines then use seq(0.01,0.99,0.01)


## ASP calculatoin
```{r}
comp_ASP6(rq1.pred, myp=seq(0.9,0.1,-0.1), mydata1$eventtime[-train.idx],
			mydata1$status[-train.idx], 10)
			
comp_ASP6(qrf1.pred, myp=seq(0.9,0.1,-0.1), mydata1$eventtime[-train.idx],
			mydata1$status[-train.idx], 10)

comp_ASP6(gbm.res, myp=seq(0.9,0.1,-0.1), mydata1$eventtime[-train.idx],
			mydata1$status[-train.idx], 10)
```

## To compute ASP for other survival models, you have to have survival times matrix
## First column is survival times for survival prob=0.9, 
## next column is survival times for survival prob=0.8, and so on until prob=0.1
## So if you have 200 observations then your survival time matrix should be 200 by 9

